{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "#### 1. Imports\n",
    "#### 2. Load data\n",
    "#### 3. Use Checklist to perturb data\n",
    "- 3.1 Change names\n",
    "- 3.2 Change location\n",
    "- 3.3 Change numbers\n",
    "#### 4. Train LSTM\n",
    "#### 5. Load fine-tuned DistilBERT\n",
    "#### 6. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "import os.path\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iob2_file(path):\n",
    "    \"\"\"\n",
    "    read in conll file\n",
    "    \n",
    "    :param path: path to read from\n",
    "    :returns: list with sequences of words and labels for each sentence\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if line[0] == '#':\n",
    "                continue # skip comments\n",
    "            tok = line.split('\\t')\n",
    "\n",
    "            current_words.append(tok[1])\n",
    "            current_tags.append(tok[2])\n",
    "        else:\n",
    "            if current_words:  # skip empty lines\n",
    "                data.append((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != []:\n",
    "        data.append((current_words, current_tags))\n",
    "    return data\n",
    "\n",
    "train_data= read_iob2_file('data//en_ewt-ud-train.iob2')\n",
    "dev_data = read_iob2_file('data//en_ewt-ud-dev.iob2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DIM_EMBEDDING = 100\n",
    "LSTM_HIDDEN = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 7\n",
    "PAD = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, pad_unk):\n",
    "        \"\"\"\n",
    "        A convenience class that can help store a vocabulary\n",
    "        and retrieve indices for inputs.\n",
    "        \"\"\"\n",
    "        self.pad_unk = pad_unk\n",
    "        self.word2idx = {self.pad_unk: 0}\n",
    "        self.idx2word = [self.pad_unk]\n",
    "\n",
    "    def getIdx(self, word, add=False):\n",
    "        if word not in self.word2idx:\n",
    "            if add:\n",
    "                self.word2idx[word] = len(self.idx2word)\n",
    "                self.idx2word.append(word)\n",
    "            else:\n",
    "                return self.word2idx[self.pad_unk]\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def getWord(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "\n",
    "max_len = max([len(x[0]) for x in train_data ])\n",
    "\n",
    "# Create vocabularies for both the tokens\n",
    "# and the tags\n",
    "token_vocab = Vocab(PAD)\n",
    "label_vocab = Vocab(PAD)\n",
    "id_to_token = [PAD]\n",
    "\n",
    "for tokens, tags in train_data:\n",
    "    for token in tokens:\n",
    "        token_vocab.getIdx(token, True)\n",
    "    for tag in tags:\n",
    "        label_vocab.getIdx(tag, True)\n",
    "\n",
    "NWORDS = len(token_vocab.idx2word)\n",
    "NTAGS = len(label_vocab.idx2word)\n",
    "\n",
    "# convert text data with labels to indices\n",
    "def data2feats(inputData, word_vocab, label_vocab):\n",
    "    feats = torch.zeros((len(inputData), max_len), dtype=torch.long)\n",
    "    labels = torch.zeros((len(inputData), max_len), dtype=torch.long)\n",
    "    for sentPos, sent in enumerate(inputData):\n",
    "        for wordPos, word in enumerate(sent[0][:max_len]):\n",
    "            wordIdx = word_vocab.getIdx(word)\n",
    "            feats[sentPos][wordPos] = wordIdx\n",
    "        for labelPos, label in enumerate(sent[1][:max_len]):\n",
    "            labelIdx = label_vocab.getIdx(label)\n",
    "            labels[sentPos][labelPos] = labelIdx\n",
    "    return feats, labels\n",
    "\n",
    "train_features, train_labels = data2feats(train_data, token_vocab, label_vocab)\n",
    "dev_feats, dev_labels = data2feats(dev_data, token_vocab, label_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Checklist to perturb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "dataset = []\n",
    "for sentence in dev_data:\n",
    "    dataset.append(\" \".join(sentence[0]))\n",
    "pdataset = list(nlp.pipe(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names_sents = []\n",
    "new_names_data = []\n",
    "# nsamples = how many 'name' sentences we want to take into account\n",
    "# n = represents number of sentences that we want to generate for each 'name' sentence\n",
    "t_names = Perturb.perturb(pdataset, Perturb.change_names, n=2)\n",
    "original_sentences = []\n",
    "for sentences in t_names.data:\n",
    "    original_sentences.append(sentences[0])\n",
    "# Tokenize\n",
    "for sentences in t_names.data:\n",
    "    for sentence in sentences:\n",
    "        new_names_sents.append(sentence.split())\n",
    "# Assign NER tags to the generated data\n",
    "for index, new_sentence in enumerate(new_names_sents):\n",
    "    for sentence in dev_data:\n",
    "        if new_sentence == sentence[0]:\n",
    "            ner_tag = sentence[1]\n",
    "    if index % 3 != 0:\n",
    "        new_names_data.append((new_names_sents[index],ner_tag))\n",
    "\n",
    "changed_names_feats, dev_names_labels = data2feats(new_names_data, token_vocab, label_vocab)\n",
    "\n",
    "# Create gold labels file: index<TAB>word<TAB>label. \n",
    "with open(os.path.join('data', 'gold_names.iob2'), 'w') as f:\n",
    "    for sentence, tag in new_names_data:\n",
    "        for index, (token, pred) in enumerate(zip(sentence, tag)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loc_sents = []\n",
    "new_location_data = []\n",
    "# nsamples = how many 'location' sentences we want to take into account\n",
    "# n = represents number of sentences that we want to generate for each 'name' sentence\n",
    "t_location = Perturb.perturb(pdataset, Perturb.change_location, n=2)\n",
    "original_sentences = []\n",
    "for sentences in t_location.data:\n",
    "    original_sentences.append(sentences[0])\n",
    "# Tokenize\n",
    "for sentences in t_location.data:\n",
    "    for sentence in sentences:\n",
    "        new_loc_sents.append(sentence.split())\n",
    "# Assign NER tags to the generated data\n",
    "for index, new_sentence in enumerate(new_loc_sents):\n",
    "    for sentence in dev_data:\n",
    "        if new_sentence == sentence[0]:\n",
    "            ner_tag = sentence[1]\n",
    "    if index % 3 != 0:\n",
    "        new_location_data.append((new_loc_sents[index],ner_tag))\n",
    "\n",
    "changed_location_feats, dev_location_labels = data2feats(new_location_data, token_vocab, label_vocab)\n",
    "\n",
    "# Create gold labels file: index<TAB>word<TAB>label. \n",
    "with open(os.path.join('data', 'gold_location.iob2'), 'w') as f:\n",
    "    for sentence, tag in new_location_data:\n",
    "        for index, (token, pred) in enumerate(zip(sentence, tag)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_number_sents = []\n",
    "new_number_data = []\n",
    "# nsamples = how many 'number' sentences we want to take into account\n",
    "# n = represents number of sentences that we want to generate for each 'name' sentence\n",
    "t_number = Perturb.perturb(pdataset, Perturb.change_number, n=2)\n",
    "original_sentences = []\n",
    "for sentences in t_number.data:\n",
    "    original_sentences.append(sentences[0])\n",
    "# Tokenize\n",
    "for sentences in t_number.data:\n",
    "    for sentence in sentences:\n",
    "        new_number_sents.append(sentence.split())\n",
    "# Assign NER tags to the generated data\n",
    "for index, new_sentence in enumerate(new_number_sents):\n",
    "    for sentence in dev_data:\n",
    "        if new_sentence == sentence[0]:\n",
    "            ner_tag = sentence[1]\n",
    "    if index % 3 != 0:\n",
    "        new_number_data.append((new_number_sents[index],ner_tag))\n",
    "\n",
    "changed_number_feats, dev_numbers_labels = data2feats(new_number_data, token_vocab, label_vocab)\n",
    "\n",
    "# Create gold labels file: index<TAB>word<TAB>label. \n",
    "with open(os.path.join('data', 'gold_numbers.iob2'), 'w') as f:\n",
    "    for sentence, tag in new_number_data:\n",
    "        for index, (token, pred) in enumerate(zip(sentence, tag)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model overview: \n",
      "LangID(\n",
      "  (word_embeddings): Embedding(19674, 100)\n",
      "  (bilstm): LSTM(100, 50, batch_first=True)\n",
      "  (hidden_to_tag): Linear(in_features=50, out_features=8, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LangID(nn.Module):\n",
    "    def __init__(self, embed_dim, lstm_dim, vocab_dim):\n",
    "        super(LangID, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_dim, embed_dim)\n",
    "        self.bilstm = nn.LSTM(embed_dim, lstm_dim, bidirectional=False, batch_first=True)\n",
    "        self.hidden_to_tag = nn.Linear(lstm_dim, NTAGS)\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        word_vectors = self.word_embeddings(inputs)\n",
    "        bilstm_out, _ = self.bilstm(word_vectors)\n",
    "        y = self.hidden_to_tag(bilstm_out)\n",
    "        return y # softmax this in order to get probs, check out for axis, has to sum up to 1\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            data_feats, data_labels = data2feats(inputs, token_vocab, label_vocab)\n",
    "\n",
    "            logits = self.forward(data_feats)\n",
    "            probabilities = self.softmax(logits)\n",
    "            return torch.argmax(probabilities, 2)\n",
    "\n",
    "\n",
    "# define the model\n",
    "langid_model = LangID(DIM_EMBEDDING, LSTM_HIDDEN, NWORDS)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n",
    "optimizer = optim.Adam(langid_model.parameters(), lr=LEARNING_RATE)\n",
    "print('model overview: ')\n",
    "print(langid_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to batches\n",
    "num_batches = int(len(train_features)/BATCH_SIZE)\n",
    "train_feats_batches = train_features[:BATCH_SIZE*num_batches].view(num_batches, BATCH_SIZE, max_len)\n",
    "train_labels_batches = train_labels[:BATCH_SIZE*num_batches].view(num_batches, BATCH_SIZE, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   loss      Train acc.\n",
      "0       272.11    0.9461\n",
      "1       112.39    0.9671\n",
      "2       59.21     0.9826\n",
      "3       35.11     0.9902\n",
      "4       22.76     0.9939\n",
      "5       16.54     0.9955\n",
      "6       12.23     0.9967\n"
     ]
    }
   ],
   "source": [
    "print('epoch   loss      Train acc.')\n",
    "for epoch in range(EPOCHS):\n",
    "    langid_model.train() \n",
    "    langid_model.zero_grad()\n",
    "\n",
    "    # Loop over batches\n",
    "    loss = 0\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for batchIdx in range(0, num_batches):\n",
    "        output_scores = langid_model.forward(train_feats_batches[batchIdx])\n",
    "        \n",
    "        output_scores = output_scores.view(BATCH_SIZE * max_len, -1)\n",
    "        flat_labels = train_labels_batches[batchIdx].view(BATCH_SIZE * max_len)\n",
    "        batch_loss = loss_function(output_scores, flat_labels)\n",
    "\n",
    "        predicted_labels = torch.argmax(output_scores, 1)\n",
    "        predicted_labels = predicted_labels.view(BATCH_SIZE, max_len)\n",
    "\n",
    "        # Run backward pass\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        langid_model.zero_grad()\n",
    "        loss += batch_loss.item()\n",
    "        # Update the number of correct tags and total tags\n",
    "        for gold_sent, pred_sent in zip(train_labels_batches[batchIdx], predicted_labels):\n",
    "            for gold_label, pred_label in zip(gold_sent, pred_sent):\n",
    "                if gold_label != 0:\n",
    "                    total += 1\n",
    "                    if gold_label == pred_label:\n",
    "                        match+= 1\n",
    "    print('{0: <8}{1: <10}{2}'.format(epoch, '{:.2f}'.format(loss/num_batches), '{:.4f}'.format(match / total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load our finetuned model\n",
    "fine_tuned = AutoModelForTokenClassification.from_pretrained(\"full_distilBERT/checkpoint-1568/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(path):\n",
    "    \"\"\"\n",
    "    get sentences from conll file\n",
    "    \n",
    "    :param path: path to read from\n",
    "    :returns: list with tokenized sentences\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if line[:6] == '# text':\n",
    "                data.append(line[9:])\n",
    "    return data\n",
    "\n",
    "dev_sentences = get_sentences('data//en_ewt-ud-dev.iob2')\n",
    "dev_sents_tokenized = []\n",
    "for sentence in dev_data:\n",
    "    dev_sents_tokenized.append(sentence[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionTags = []\n",
    "\n",
    "def run_eval_bert(sentences, gold_labels):\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for sents, labels in zip(sentences, gold_labels):\n",
    "        inputs = tokenizer(sents, return_tensors=\"pt\", padding=True, truncation=True, is_split_into_words=True)\n",
    "        predictionTagOneSentence = []\n",
    "        with torch.no_grad():\n",
    "            word_ids = inputs.word_ids()\n",
    "            # tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].flatten())\n",
    "            logits = fine_tuned(**inputs).logits\n",
    "            predictions = torch.argmax(logits, dim=-1).flatten()\n",
    "            previous_word_idx = None\n",
    "            for idx, word_idx in enumerate(word_ids):\n",
    "                if previous_word_idx != word_idx and word_idx is not None:\n",
    "                    predictionTagOneSentence.append(label_vocab.idx2word[predictions[idx].item()])\n",
    "                previous_word_idx = word_idx\n",
    "        predictionTags.append(predictionTagOneSentence)\n",
    "\n",
    "        # Loop through gold labels\n",
    "        for goldLabel, predLabel in zip(labels, predictions):\n",
    "            if goldLabel.item() != 0:\n",
    "                total += 1\n",
    "                if goldLabel.item() == predLabel.item():\n",
    "                    match+= 1\n",
    "    return(match/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionsTags = []\n",
    "sentences = []\n",
    "\n",
    "def run_eval_lstm(feats_batches, labels_batches):\n",
    "    langid_model.eval()\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for sents, labels in zip(feats_batches, labels_batches):\n",
    "        output_scores = langid_model.forward(sents)\n",
    "        predicted_tags  = torch.argmax(output_scores, 2)\n",
    "        for sentence in sents:\n",
    "            sentenceWords = []\n",
    "            for wordIndex in sentence:\n",
    "                sentenceWords.append(token_vocab.getWord(wordIndex.item()))\n",
    "            sentences.append(sentenceWords)\n",
    "        for sentenceTags in predicted_tags:\n",
    "                predictionTagOneSentence = []\n",
    "                for tag in sentenceTags:\n",
    "                    predictionTagOneSentence.append(label_vocab.idx2word[tag.item()])\n",
    "                predictionsTags.append(predictionTagOneSentence)\n",
    "        for goldSent, predSent in zip(labels, predicted_tags):\n",
    "            for goldLabel, predLabel in zip(goldSent, predSent):\n",
    "                if goldLabel.item() != 0:\n",
    "                    total += 1\n",
    "                    if goldLabel.item() == predLabel.item():\n",
    "                        match+= 1\n",
    "    return(match/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dev data: 0.9568\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictionsTags = []\n",
    "\n",
    "num_batches_dev = int(len(dev_feats)/BATCH_SIZE)\n",
    "\n",
    "dev_feats_batches = dev_feats[:BATCH_SIZE*num_batches_dev].view(num_batches_dev, BATCH_SIZE, max_len)\n",
    "dev_labels_batches = dev_labels[:BATCH_SIZE*num_batches_dev].view(num_batches_dev, BATCH_SIZE, max_len)\n",
    "score = run_eval_lstm(dev_feats_batches, dev_labels_batches)\n",
    "\n",
    "print('Accuracy for dev data: {:.4f}'.format(score))\n",
    "\n",
    "with open(os.path.join('data', 'lstm_predictions_dev.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictionsTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/lstm_predictions_dev.iob2 data/en_ewt-ud-dev.iob2  <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed names data: \u001b[0m 0.9048\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictionsTags = []\n",
    "\n",
    "num_batches_changed_names = int(len(changed_names_feats)/BATCH_SIZE)\n",
    "\n",
    "changed_names_feats_batches = changed_names_feats[:BATCH_SIZE*num_batches_changed_names].view(num_batches_changed_names, BATCH_SIZE, max_len)\n",
    "changed_names_labels_batches = dev_names_labels[:BATCH_SIZE*num_batches_changed_names].view(num_batches_changed_names, BATCH_SIZE, max_len)\n",
    "score = run_eval_lstm(changed_names_feats_batches, changed_names_labels_batches)\n",
    "\n",
    "print('\\033[32mAccuracy for changed names data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open(os.path.join('data', 'lstm_predictions_names.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictionsTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# python3 span_f1.py data/lstm_predictions_names.iob2 data/gold_names.iob2  <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed location data: \u001b[0m 0.9204\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictionsTags = []\n",
    "\n",
    "num_batches_changed_location = int(len(changed_location_feats)/BATCH_SIZE)\n",
    "\n",
    "changed_location_feats_batches = changed_location_feats[:BATCH_SIZE*num_batches_changed_location].view(num_batches_changed_location, BATCH_SIZE, max_len)\n",
    "changed_location_labels_batches = dev_location_labels[:BATCH_SIZE*num_batches_changed_location].view(num_batches_changed_location, BATCH_SIZE, max_len)\n",
    "score = run_eval_lstm(changed_location_feats_batches, changed_location_labels_batches)\n",
    "\n",
    "print('\\033[32mAccuracy for changed location data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open(os.path.join('data', 'lstm_predictions_location.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictionsTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# python3 span_f1.py data/lstm_predictions_location.iob2 data/gold_location.iob2  <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed number data: \u001b[0m 0.9314\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictionsTags = []\n",
    "\n",
    "num_batches_changed_number = int(len(changed_number_feats)/BATCH_SIZE)\n",
    "\n",
    "changed_number_feats_batches = changed_number_feats[:BATCH_SIZE*num_batches_changed_number].view(num_batches_changed_number, BATCH_SIZE, max_len)\n",
    "changed_number_labels_batches = dev_numbers_labels[:BATCH_SIZE*num_batches_changed_number].view(num_batches_changed_number, BATCH_SIZE, max_len)\n",
    "score = run_eval_lstm(changed_number_feats_batches, changed_number_labels_batches)\n",
    "\n",
    "print('\\033[32mAccuracy for changed number data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open(os.path.join('data', 'lstm_predictions_numbers.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictionsTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# python3 span_f1.py data/lstm_predictions_numbers.iob2 data/gold_numbers.iob2  <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dev data: 0.8983\n",
      "['where', 'can', 'I', 'get', 'morcillas', 'in', 'tampa', 'bay', ',', 'I', 'will', 'like', 'the', 'argentinian', 'type', ',', 'but', 'I', 'will', 'to', 'try', 'anothers', 'please', '?']\n",
      "2001\n"
     ]
    }
   ],
   "source": [
    "predictionTags = []\n",
    "\n",
    "score = run_eval_bert(dev_sents_tokenized, dev_labels)\n",
    "\n",
    "print('Accuracy for dev data: {:.4f}'.format(score))\n",
    "\n",
    "print(dev_data[0][0])\n",
    "print(len(predictionTags))\n",
    "\n",
    "with open(os.path.join('data', 'bert_predictions_dev.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(dev_sents_tokenized, predictionTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/bert_predictions_dev.iob2 data/en_ewt-ud-dev.iob2  <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dev data: 0.7264\n",
      "['Which', 'of', 'these', 'do', 'you', 'like', ':', 'McDonald', 's', ',', 'Burger', 'King', ',', 'Taco', 'Bell', ',', 'Wendy', 's', '?']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O', 'B-ORG', 'I-ORG', 'O']\n"
     ]
    }
   ],
   "source": [
    "predictionTags = []\n",
    "\n",
    "names_sents_tokenized = []\n",
    "for sentence in new_names_data:\n",
    "    names_sents_tokenized.append(sentence[0])\n",
    "\n",
    "score = run_eval_bert(names_sents_tokenized, dev_names_labels)\n",
    "\n",
    "print('Accuracy for names data: {:.4f}'.format(score))\n",
    "\n",
    "print(names_sents_tokenized[0])\n",
    "print(predictionTags[0])\n",
    "\n",
    "with open(os.path.join('data', 'bert_predictions_names.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(names_sents_tokenized, predictionTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "# python3 span_f1.py data/bert_predictions_names.iob2 data/gold_names.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for location data: 0.7677\n",
      "['There', 'are', 'way', 'more', 'stranger', 'names', 'in', 'the', 'U.S', 'for', 'areas', 'than', 'St.', 'Paul', '.']\n",
      "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'I-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "predictionTags = []\n",
    "\n",
    "location_sents_tokanized = []\n",
    "for sentence in new_location_data:\n",
    "    location_sents_tokanized.append(sentence[0])\n",
    "\n",
    "score = run_eval_bert(location_sents_tokanized, dev_location_labels)\n",
    "\n",
    "print('Accuracy for location data: {:.4f}'.format(score))\n",
    "\n",
    "print(location_sents_tokanized[0])\n",
    "print(predictionTags[0])\n",
    "\n",
    "with open(os.path.join('data', 'bert_predictions_location.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(location_sents_tokanized, predictionTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "# python3 span_f1.py data/bert_predictions_location.iob2 data/gold_location.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for numbers data: 0.8547\n",
      "['2', 'cup', 'of', 'empanadas']\n",
      "['O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "predictionTags = []\n",
    "\n",
    "numbers_sents_tokanized = []\n",
    "for sentence in new_number_data:\n",
    "    numbers_sents_tokanized.append(sentence[0])\n",
    "\n",
    "score = run_eval_bert(numbers_sents_tokanized, dev_numbers_labels)\n",
    "\n",
    "print('Accuracy for numbers data: {:.4f}'.format(score))\n",
    "\n",
    "print(numbers_sents_tokanized[0])\n",
    "print(predictionTags[0])\n",
    "\n",
    "with open(os.path.join('data', 'bert_predictions_numbers.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(numbers_sents_tokanized, predictionTags):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "# python3 span_f1.py data/bert_predictions_numbers.iob2 data/gold_numbers.iob2 <- run this in terminal to get span f1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
