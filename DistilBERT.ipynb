{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from datasets import Dataset\n",
    "import os.path\n",
    "import sklearn\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iob2_file(path):\n",
    "    \"\"\"\n",
    "    read in conll file\n",
    "    \n",
    "    :param path: path to read from\n",
    "    :returns: list with sequences of words and labels for each sentence\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if line[0] == '#':\n",
    "                continue # skip comments\n",
    "            tok = line.split('\\t')\n",
    "\n",
    "            current_words.append(tok[1])\n",
    "            current_tags.append(tok[2])\n",
    "        else:\n",
    "            if current_words:  # skip empty lines\n",
    "                data.append((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != []:\n",
    "        data.append((current_words, current_tags))\n",
    "    return data\n",
    "\n",
    "train_data= read_iob2_file('data//en_ewt-ud-train.iob2')\n",
    "dev_data = read_iob2_file('data//en_ewt-ud-dev.iob2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DIM_EMBEDDING = 100\n",
    "LSTM_HIDDEN = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5\n",
    "PAD = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, pad_unk):\n",
    "        \"\"\"\n",
    "        A convenience class that can help store a vocabulary\n",
    "        and retrieve indices for inputs.\n",
    "        \"\"\"\n",
    "        self.pad_unk = pad_unk\n",
    "        self.word2idx = {self.pad_unk: 0}\n",
    "        self.idx2word = [self.pad_unk]\n",
    "\n",
    "    def getIdx(self, word, add=False):\n",
    "        if word not in self.word2idx:\n",
    "            if add:\n",
    "                self.word2idx[word] = len(self.idx2word)\n",
    "                self.idx2word.append(word)\n",
    "            else:\n",
    "                return self.word2idx[self.pad_unk]\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def getWord(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "\n",
    "max_len = max([len(x[0]) for x in train_data ])\n",
    "\n",
    "# Create vocabularies for both the tokens\n",
    "# and the tags\n",
    "token_vocab = Vocab(PAD)\n",
    "label_vocab = Vocab(PAD)\n",
    "id_to_token = [PAD]\n",
    "\n",
    "for tokens, tags in train_data:\n",
    "    for token in tokens:\n",
    "        token_vocab.getIdx(token, True)\n",
    "    for tag in tags:\n",
    "        label_vocab.getIdx(tag, True)\n",
    "\n",
    "NWORDS = len(token_vocab.idx2word)\n",
    "NTAGS = len(label_vocab.idx2word)\n",
    "\n",
    "# convert text data with labels to indices\n",
    "def data2feats(inputData, word_vocab, label_vocab):\n",
    "    feats = torch.zeros((len(inputData), max_len), dtype=torch.long)\n",
    "    labels = torch.zeros((len(inputData), max_len), dtype=torch.long)\n",
    "    for sentPos, sent in enumerate(inputData):\n",
    "        for wordPos, word in enumerate(sent[0][:max_len]):\n",
    "            wordIdx = word_vocab.getIdx(word)\n",
    "            feats[sentPos][wordPos] = wordIdx\n",
    "        for labelPos, label in enumerate(sent[1][:max_len]):\n",
    "            labelIdx = label_vocab.getIdx(label)\n",
    "            labels[sentPos][labelPos] = labelIdx\n",
    "    return feats, labels\n",
    "\n",
    "train_features, train_labels = data2feats(train_data, token_vocab, label_vocab)\n",
    "dev_feats, dev_labels = data2feats(dev_data, token_vocab, label_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected data format\\\n",
    "{\\\n",
    "    'id': '0',\\\n",
    " 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 8, 8, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0],\\\n",
    " 'tokens': ['@paulwalk', 'It', \"'s\", 'the', 'view', 'from', 'where', 'I', \"'m\", 'living', 'for', 'two', 'weeks', '.', 'Empire', 'State', 'Building', '=', 'ESB', '.', 'Pretty', 'bad', 'storm', 'here', 'last', 'evening', '.']\\\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Where', 'in', 'the', 'world', 'is', 'Iguazu', '?'], ['O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'])\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for wnut_17 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/wnut_17\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# wnut = load_dataset(\"wnut_17\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "# label_list = wnut[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "# example = wnut[\"train\"][0]\n",
    "\n",
    "# def tokenize_and_align_labels(examples):\n",
    "#     tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "#     labels = []\n",
    "#     for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "#         word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "#         previous_word_idx = None\n",
    "#         label_ids = []\n",
    "#         for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "#             if word_idx is None:\n",
    "#                 label_ids.append(-100)\n",
    "#             elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "#                 label_ids.append(label[word_idx])\n",
    "#             else:\n",
    "#                 label_ids.append(-100)\n",
    "#             previous_word_idx = word_idx\n",
    "#         labels.append(label_ids)\n",
    "\n",
    "#     tokenized_inputs[\"labels\"] = labels\n",
    "#     return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b022c6e55f6453090b4e2fbec1d5377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3394 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fea0b51a9044fa9bf41f1eafd79eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1009 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19cbe4e3fcb42808534994c386d8d4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1287 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenized_wnut = wnut.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "# seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "# labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     predictions, labels = p\n",
    "#     predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "#     true_predictions = [\n",
    "#         [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "#     true_labels = [\n",
    "#         [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "\n",
    "#     results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "#     return {\n",
    "#         \"precision\": results[\"overall_precision\"],\n",
    "#         \"recall\": results[\"overall_recall\"],\n",
    "#         \"f1\": results[\"overall_f1\"],\n",
    "#         \"accuracy\": results[\"overall_accuracy\"],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2label = {\n",
    "#     0: \"O\",\n",
    "#     1: \"B-corporation\",\n",
    "#     2: \"I-corporation\",\n",
    "#     3: \"B-creative-work\",\n",
    "#     4: \"I-creative-work\",\n",
    "#     5: \"B-group\",\n",
    "#     6: \"I-group\",\n",
    "#     7: \"B-location\",\n",
    "#     8: \"I-location\",\n",
    "#     9: \"B-person\",\n",
    "#     10: \"I-person\",\n",
    "#     11: \"B-product\",\n",
    "#     12: \"I-product\",\n",
    "# }\n",
    "# label2id = {\n",
    "#     \"O\": 0,\n",
    "#     \"B-corporation\": 1,\n",
    "#     \"I-corporation\": 2,\n",
    "#     \"B-creative-work\": 3,\n",
    "#     \"I-creative-work\": 4,\n",
    "#     \"B-group\": 5,\n",
    "#     \"I-group\": 6,\n",
    "#     \"B-location\": 7,\n",
    "#     \"I-location\": 8,\n",
    "#     \"B-person\": 9,\n",
    "#     \"I-person\": 10,\n",
    "#     \"B-product\": 11,\n",
    "#     \"I-product\": 12,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = AutoModelForTokenClassification.from_pretrained(\n",
    "#     \"distilbert/distilbert-base-uncased\", num_labels=13, id2label=id2label, label2id=label2id\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c58fec37f8c4a568f1ec4eb211827f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f609bf56e7144fcbcf49ea5e1007e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29800260066986084, 'eval_precision': 0.5586734693877551, 'eval_recall': 0.20296570898980537, 'eval_f1': 0.29775662814411963, 'eval_accuracy': 0.9373690735753067, 'eval_runtime': 10.316, 'eval_samples_per_second': 124.757, 'eval_steps_per_second': 7.852, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57eeeb392bd949a08487ce8dc39f43ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28243619203567505, 'eval_precision': 0.5871559633027523, 'eval_recall': 0.2965708989805375, 'eval_f1': 0.3940886699507389, 'eval_accuracy': 0.9416442221367193, 'eval_runtime': 6.4864, 'eval_samples_per_second': 198.414, 'eval_steps_per_second': 12.488, 'epoch': 2.0}\n",
      "{'train_runtime': 128.5943, 'train_samples_per_second': 52.786, 'train_steps_per_second': 3.313, 'train_loss': 0.21657641057117444, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=426, training_loss=0.21657641057117444, metrics={'train_runtime': 128.5943, 'train_samples_per_second': 52.786, 'train_steps_per_second': 3.313, 'train_loss': 0.21657641057117444, 'epoch': 2.0})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"wnut_model\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=16,\n",
    "#     per_device_eval_batch_size=16,\n",
    "#     num_train_epochs=2,\n",
    "#     weight_decay=0.01,\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "#     # push_to_hub=True,\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_wnut[\"train\"],\n",
    "#     eval_dataset=tokenized_wnut[\"test\"],\n",
    "#     tokenizer=tokenizer,\n",
    "#     data_collator=data_collator,\n",
    "#     compute_metrics=compute_metrics,\n",
    "# )\n",
    "\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'where',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'is',\n",
       " 'i',\n",
       " '##gua',\n",
       " '##zu',\n",
       " '?',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "example = train_data[0]\n",
    "tokenized_input = tokenizer(example[0], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 2073, 1999, 1996, 2088, 2003, 1045, 19696, 9759, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 1, 1, 1, 1, 2, 1]}\n",
      "{'input_ids': [101, 2073, 2064, 1045, 2131, 22822, 6895, 25816, 1999, 9925, 3016, 1010, 1045, 2097, 2066, 1996, 23157, 15830, 2828, 1010, 2021, 1045, 2097, 2000, 3046, 2178, 2015, 3531, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2073, 1999, 1996, 2088, 2003, 1045, 19696, 9759, 1029, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, 1, 1, 1, 1, 2, -100, -100, 1, -100]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\n",
    "\n",
    "def align_labels(tokenized_input, labels):\n",
    "  word_ids = tokenized_input.word_ids()  # Get word IDs for each token\n",
    "  aligned_labels = []\n",
    "  previous_word_idx = None\n",
    "  for word_idx in word_ids:\n",
    "    # Set special tokens and padding to -100 (ignored during training)\n",
    "    if word_idx is None or word_idx == tokenizer.pad_token_id:\n",
    "      aligned_labels.append(-100)\n",
    "    # Only label the first token of a word (assuming B-LOC etc. are for the whole word) \n",
    "    elif word_idx != previous_word_idx:\n",
    "      aligned_labels.append(labels[word_idx])\n",
    "    else:\n",
    "      aligned_labels.append(-100)\n",
    "    previous_word_idx = word_idx\n",
    "  return aligned_labels\n",
    "\n",
    "# TRAIN DATA\n",
    "tokenized_train = []\n",
    "for sentence, labels in train_data:\n",
    "  tokenized_input = tokenizer(sentence, is_split_into_words=True)\n",
    "  labelsIndices = []\n",
    "  for label in labels:\n",
    "    labelsIndices.append(label_vocab.getIdx(label))\n",
    "  tokenized_input['labels'] = labelsIndices\n",
    "  tokenized_train.append(tokenized_input)  # Store tokenized data and labels together\n",
    "print(tokenized_train[0])\n",
    "\n",
    "# Add aligned labels to each data point\n",
    "for tokenized_input in tokenized_train:\n",
    "  aligned_labels = align_labels(tokenized_input, tokenized_input['labels'])\n",
    "  tokenized_input['labels'] = aligned_labels\n",
    "\n",
    "# DEV DATA\n",
    "tokenized_dev = []\n",
    "for sentence, labels in dev_data:\n",
    "  tokenized_input = tokenizer(sentence, is_split_into_words=True)\n",
    "  labelsIndices = []\n",
    "  for label in labels:\n",
    "    labelsIndices.append(label_vocab.getIdx(label))\n",
    "  tokenized_input['labels'] = labelsIndices\n",
    "  tokenized_dev.append(tokenized_input)  # Store tokenized data and labels together\n",
    "print(tokenized_dev[0])\n",
    "\n",
    "# Add aligned labels to each data point\n",
    "for tokenized_input in tokenized_dev:\n",
    "  aligned_labels = align_labels(tokenized_input, tokenized_input['labels'])\n",
    "  tokenized_input['labels'] = aligned_labels\n",
    "\n",
    "tokenized_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "# print(tokenized_wnut[\"train\"][3])\n",
    "# print(tokenized_wnut[\"train\"][3]['ner_tags'])\n",
    "print(tokenized_wnut[\"train\"][3]['labels']) # have it \n",
    "# print(tokenized_wnut[\"train\"][3]['input_ids'])\n",
    "# print(tokenized_wnut[\"train\"][3]['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "# labels = [label_list[i] for i in example[1]]\n",
    "\n",
    "\n",
    "# def compute_metrics(p):\n",
    "#     predictions, labels = p\n",
    "#     predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "#     true_predictions = [\n",
    "#         [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "#     true_labels = [\n",
    "#         [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "#         for prediction, label in zip(predictions, labels)\n",
    "#     ]\n",
    "\n",
    "#     results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "#     return {\n",
    "#         \"precision\": results[\"overall_precision\"],\n",
    "#         \"recall\": results[\"overall_recall\"],\n",
    "#         \"f1\": results[\"overall_f1\"],\n",
    "#         \"accuracy\": results[\"overall_accuracy\"],\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"distilbert/distilbert-base-uncased\", num_labels=NTAGS\n",
    "    # , id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Changing param values is not allowed. Param with key='logging_dir' was already logged with value='testing_bert/runs/May18_10-18-20_airuzivarichard.lan' for run ID='876b6b1581644298bee74b41b6054c5e'. Attempted logging new value 'testing_bert/runs/May18_10-20-11_airuzivarichard.lan'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:1047\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m params:\n\u001b[0;32m-> 1047\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_run_param(run_info, param)\n\u001b[1;32m   1048\u001b[0m \u001b[39mfor\u001b[39;00m metric \u001b[39min\u001b[39;00m metrics:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:952\u001b[0m, in \u001b[0;36mFileStore._log_run_param\u001b[0;34m(self, run_info, param)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(param_path):\n\u001b[0;32m--> 952\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_new_param_value(\n\u001b[1;32m    953\u001b[0m         param_path\u001b[39m=\u001b[39mparam_path,\n\u001b[1;32m    954\u001b[0m         param_key\u001b[39m=\u001b[39mparam\u001b[39m.\u001b[39mkey,\n\u001b[1;32m    955\u001b[0m         run_id\u001b[39m=\u001b[39mrun_info\u001b[39m.\u001b[39mrun_id,\n\u001b[1;32m    956\u001b[0m         new_value\u001b[39m=\u001b[39mwriteable_param_value,\n\u001b[1;32m    957\u001b[0m     )\n\u001b[1;32m    958\u001b[0m make_containing_dirs(param_path)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:972\u001b[0m, in \u001b[0;36mFileStore._validate_new_param_value\u001b[0;34m(self, param_path, param_key, run_id, new_value)\u001b[0m\n\u001b[1;32m    971\u001b[0m \u001b[39mif\u001b[39;00m current_value \u001b[39m!=\u001b[39m new_value:\n\u001b[0;32m--> 972\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    973\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mChanging param values is not allowed. Param with key=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparam_key\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was already\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    974\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m logged with value=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mcurrent_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m for run ID=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrun_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Attempted logging\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    975\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m new value \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnew_value\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    976\u001b[0m         databricks_pb2\u001b[39m.\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    977\u001b[0m     )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='testing_bert/runs/May18_10-18-20_airuzivarichard.lan' for run ID='876b6b1581644298bee74b41b6054c5e'. Attempted logging new value 'testing_bert/runs/May18_10-20-11_airuzivarichard.lan'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 24\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtesting_bert\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39m# push_to_hub=True,\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m     15\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     16\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39m# compute_metrics=compute_metrics,\u001b[39;00m\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 24\u001b[0m trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m         args\u001b[39m=\u001b[39margs,\n\u001b[1;32m   1541\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m         trial\u001b[39m=\u001b[39mtrial,\n\u001b[1;32m   1543\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1787\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step\n\u001b[1;32m   1785\u001b[0m model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m-> 1787\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_train_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1789\u001b[0m \u001b[39m# Skip the first epochs_trained epochs to get the random state of the dataloader at the right point.\u001b[39;00m\n\u001b[1;32m   1790\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m args\u001b[39m.\u001b[39mignore_data_skip:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer_callback.py:370\u001b[0m, in \u001b[0;36mCallbackHandler.on_train_begin\u001b[0;34m(self, args, state, control)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args: TrainingArguments, state: TrainerState, control: TrainerControl):\n\u001b[1;32m    369\u001b[0m     control\u001b[39m.\u001b[39mshould_training_stop \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_event(\u001b[39m\"\u001b[39m\u001b[39mon_train_begin\u001b[39m\u001b[39m\"\u001b[39m, args, state, control)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer_callback.py:414\u001b[0m, in \u001b[0;36mCallbackHandler.call_event\u001b[0;34m(self, event, args, state, control, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_event\u001b[39m(\u001b[39mself\u001b[39m, event, args, state, control, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    413\u001b[0m     \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[0;32m--> 414\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, event)(\n\u001b[1;32m    415\u001b[0m             args,\n\u001b[1;32m    416\u001b[0m             state,\n\u001b[1;32m    417\u001b[0m             control,\n\u001b[1;32m    418\u001b[0m             model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel,\n\u001b[1;32m    419\u001b[0m             tokenizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer,\n\u001b[1;32m    420\u001b[0m             optimizer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer,\n\u001b[1;32m    421\u001b[0m             lr_scheduler\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler,\n\u001b[1;32m    422\u001b[0m             train_dataloader\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_dataloader,\n\u001b[1;32m    423\u001b[0m             eval_dataloader\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39meval_dataloader,\n\u001b[1;32m    424\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    425\u001b[0m         )\n\u001b[1;32m    426\u001b[0m         \u001b[39m# A Callback can skip the return of `control` if it doesn't change it.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:1024\u001b[0m, in \u001b[0;36mMLflowCallback.on_train_begin\u001b[0;34m(self, args, state, control, model, **kwargs)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_begin\u001b[39m(\u001b[39mself\u001b[39m, args, state, control, model\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1023\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialized:\n\u001b[0;32m-> 1024\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msetup(args, state, model)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/integrations/integration_utils.py:1015\u001b[0m, in \u001b[0;36mMLflowCallback.setup\u001b[0;34m(self, args, state, model)\u001b[0m\n\u001b[1;32m   1013\u001b[0m combined_dict_items \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(combined_dict\u001b[39m.\u001b[39mitems())\n\u001b[1;32m   1014\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(combined_dict_items), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_MAX_PARAMS_TAGS_PER_BATCH):\n\u001b[0;32m-> 1015\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ml_flow\u001b[39m.\u001b[39mlog_params(\u001b[39mdict\u001b[39m(combined_dict_items[i : i \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_MAX_PARAMS_TAGS_PER_BATCH]))\n\u001b[1;32m   1016\u001b[0m mlflow_tags \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mMLFLOW_TAGS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   1017\u001b[0m \u001b[39mif\u001b[39;00m mlflow_tags:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/tracking/fluent.py:863\u001b[0m, in \u001b[0;36mlog_params\u001b[0;34m(params, synchronous)\u001b[0m\n\u001b[1;32m    861\u001b[0m run_id \u001b[39m=\u001b[39m _get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[1;32m    862\u001b[0m params_arr \u001b[39m=\u001b[39m [Param(key, \u001b[39mstr\u001b[39m(value)) \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m params\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m--> 863\u001b[0m \u001b[39mreturn\u001b[39;00m MlflowClient()\u001b[39m.\u001b[39mlog_batch(\n\u001b[1;32m    864\u001b[0m     run_id\u001b[39m=\u001b[39mrun_id, metrics\u001b[39m=\u001b[39m[], params\u001b[39m=\u001b[39mparams_arr, tags\u001b[39m=\u001b[39m[], synchronous\u001b[39m=\u001b[39msynchronous\n\u001b[1;32m    865\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/tracking/client.py:1093\u001b[0m, in \u001b[0;36mMlflowClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_batch\u001b[39m(\n\u001b[1;32m   1025\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   1026\u001b[0m     run_id: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     synchronous: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1031\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[RunOperations]:\n\u001b[1;32m   1032\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m    Log multiple metrics, params, and/or tags.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[39m        status: FINISHED\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tracking_client\u001b[39m.\u001b[39mlog_batch(\n\u001b[1;32m   1094\u001b[0m         run_id, metrics, params, tags, synchronous\u001b[39m=\u001b[39msynchronous\n\u001b[1;32m   1095\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:444\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_batch\u001b[0;34m(self, run_id, metrics, params, tags, synchronous)\u001b[0m\n\u001b[1;32m    441\u001b[0m metrics \u001b[39m=\u001b[39m metrics[metrics_batch_size:]\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m synchronous:\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore\u001b[39m.\u001b[39mlog_batch(\n\u001b[1;32m    445\u001b[0m         run_id\u001b[39m=\u001b[39mrun_id, metrics\u001b[39m=\u001b[39mmetrics_batch, params\u001b[39m=\u001b[39mparams_batch, tags\u001b[39m=\u001b[39mtags_batch\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     run_operations_list\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    449\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstore\u001b[39m.\u001b[39mlog_batch_async(\n\u001b[1;32m    450\u001b[0m             run_id\u001b[39m=\u001b[39mrun_id,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    454\u001b[0m         )\n\u001b[1;32m    455\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/file_store.py:1058\u001b[0m, in \u001b[0;36mFileStore.log_batch\u001b[0;34m(self, run_id, metrics, params, tags)\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_run_tag(run_info, tag)\n\u001b[1;32m   1057\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[39mraise\u001b[39;00m MlflowException(e, INTERNAL_ERROR)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Changing param values is not allowed. Param with key='logging_dir' was already logged with value='testing_bert/runs/May18_10-18-20_airuzivarichard.lan' for run ID='876b6b1581644298bee74b41b6054c5e'. Attempted logging new value 'testing_bert/runs/May18_10-20-11_airuzivarichard.lan'."
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"testing_bert\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    # push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_dev,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our finetuned model\n",
    "fine_tuned = AutoModelForTokenClassification.from_pretrained(\"testing_bert/checkpoint-250/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dev data: 0.9404\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "def run_eval(feats_batches, labels_batches, model):\n",
    "    if model == 'LSTM':\n",
    "        langid_model.eval()\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for sents, labels in zip(feats_batches, labels_batches):\n",
    "        if model == 'LSTM':\n",
    "            output_scores = langid_model.forward(sents)\n",
    "            predicted_tags  = torch.argmax(output_scores, 2)\n",
    "        elif model == 'BERT':\n",
    "            output_scores = fine_tuned(sents) \n",
    "            predicted_tags  = torch.argmax(output_scores.logits, dim=-1)\n",
    "        else:\n",
    "            print('Please specify supported model.')\n",
    "            return\n",
    "        for sentence in sents:\n",
    "            sentenceWords = []\n",
    "            for wordIndex in sentence:\n",
    "                sentenceWords.append(token_vocab.getWord(wordIndex.item()))\n",
    "            sentences.append(sentenceWords)\n",
    "        for sentenceTags in predicted_tags:\n",
    "                predictionTagOneSentence = []\n",
    "                for tag in sentenceTags:\n",
    "                    predictionTagOneSentence.append(label_vocab.idx2word[tag.item()])\n",
    "                predictions.append(predictionTagOneSentence)\n",
    "        for goldSent, predSent in zip(labels, predicted_tags):\n",
    "            for goldLabel, predLabel in zip(goldSent, predSent):\n",
    "                if goldLabel.item() != 0:\n",
    "                    total += 1\n",
    "                    if goldLabel.item() == predLabel.item():\n",
    "                        match+= 1\n",
    "    return(match/total)\n",
    "\n",
    "num_batches_dev = int(len(dev_feats)/BATCH_SIZE)\n",
    "\n",
    "dev_feats_batches = dev_feats[:BATCH_SIZE*num_batches_dev].view(num_batches_dev, BATCH_SIZE, max_len)\n",
    "dev_labels_batches = dev_labels[:BATCH_SIZE*num_batches_dev].view(num_batches_dev, BATCH_SIZE, max_len)\n",
    "score = run_eval(dev_feats_batches, dev_labels_batches, 'BERT')\n",
    "\n",
    "print('Accuracy for dev data: {:.4f}'.format(score))\n",
    "\n",
    "with open(os.path.join('data', 'new_bert_predictions_dev.iob2'), 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/new_bert_predictions_dev.iob2 data/en_ewt-ud-dev.iob2  <- run this in terminal to get span f1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
