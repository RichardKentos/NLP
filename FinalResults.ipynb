{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "from checklist.perturb import Perturb\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_iob2_file(path):\n",
    "    \"\"\"\n",
    "    read in conll file\n",
    "    \n",
    "    :param path: path to read from\n",
    "    :returns: list with sequences of words and labels for each sentence\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    for line in open(path, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            if line[0] == '#':\n",
    "                continue # skip comments\n",
    "            tok = line.split('\\t')\n",
    "\n",
    "            current_words.append(tok[1])\n",
    "            current_tags.append(tok[2])\n",
    "        else:\n",
    "            if current_words:  # skip empty lines\n",
    "                data.append((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != []:\n",
    "        data.append((current_words, current_tags))\n",
    "    return data\n",
    "\n",
    "train_data= read_iob2_file('data//en_ewt-ud-train.iob2')\n",
    "dev_data = read_iob2_file('data//en_ewt-ud-dev.iob2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "DIM_EMBEDDING = 100\n",
    "LSTM_HIDDEN = 50\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 5\n",
    "PAD = '<PAD>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab():\n",
    "    def __init__(self, pad_unk):\n",
    "        \"\"\"\n",
    "        A convenience class that can help store a vocabulary\n",
    "        and retrieve indices for inputs.\n",
    "        \"\"\"\n",
    "        self.pad_unk = pad_unk\n",
    "        self.word2idx = {self.pad_unk: 0}\n",
    "        self.idx2word = [self.pad_unk]\n",
    "\n",
    "    def getIdx(self, word, add=False):\n",
    "        if word not in self.word2idx:\n",
    "            if add:\n",
    "                self.word2idx[word] = len(self.idx2word)\n",
    "                self.idx2word.append(word)\n",
    "            else:\n",
    "                return self.word2idx[self.pad_unk]\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def getWord(self, idx):\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "\n",
    "max_len = max([len(x[0]) for x in train_data ])\n",
    "\n",
    "# Create vocabularies for both the tokens\n",
    "# and the tags\n",
    "token_vocab = Vocab(PAD)\n",
    "label_vocab = Vocab(PAD)\n",
    "id_to_token = [PAD]\n",
    "\n",
    "for tokens, tags in train_data:\n",
    "    for token in tokens:\n",
    "        token_vocab.getIdx(token, True)\n",
    "    for tag in tags:\n",
    "        label_vocab.getIdx(tag, True)\n",
    "\n",
    "NWORDS = len(token_vocab.idx2word)\n",
    "NTAGS = len(label_vocab.idx2word)\n",
    "\n",
    "# convert text data with labels to indices\n",
    "def data2feats(inputData, word_vocab, label_vocab):\n",
    "    feats = torch.zeros((len(inputData), max_len), dtype=torch.long)\n",
    "    labels = torch.zeros((len(inputData), max_len), dtype=torch.long)\n",
    "    for sentPos, sent in enumerate(inputData):\n",
    "        for wordPos, word in enumerate(sent[0][:max_len]):\n",
    "            wordIdx = word_vocab.getIdx(word)\n",
    "            feats[sentPos][wordPos] = wordIdx\n",
    "        for labelPos, label in enumerate(sent[1][:max_len]):\n",
    "            labelIdx = label_vocab.getIdx(label)\n",
    "            labels[sentPos][labelPos] = labelIdx\n",
    "    return feats, labels\n",
    "\n",
    "train_features, train_labels = data2feats(train_data, token_vocab, label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"distilbert/distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=NTAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "  labels = pred.label_ids\n",
    "  preds = pred.predictions.argmax(-1)\n",
    "  flat_labels = labels.view(-1)\n",
    "  flat_preds = preds.view(-1)\n",
    "  \n",
    "  precision, recall, f1, _ = precision_recall_fscore_support(flat_labels, flat_preds, average=None)\n",
    "\n",
    "  return {\n",
    "      'precision': precision.tolist(),\n",
    "      'recall': recall.tolist(),\n",
    "      'f1': f1.tolist(),\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of training data = 12543\n",
    "Please edit the **number_of_sentences** to the desired number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=250,\n",
    "    weight_decay=0.0,\n",
    "    warmup_ratio=0.1,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=100,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    gradient_checkpointing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_sentences = 12543\n",
    "features = {'input_ids': train_features[:number_of_sentences], 'label': train_labels[:number_of_sentences]}\n",
    "train_dataset = Dataset.from_dict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part below needs to be run only **once**! - if we have the desired model saved in finetuned_bert, then you can skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~ 50s / it for 100 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:446: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f325d44519814ffd8fbf3ece2128de25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4057, 'learning_rate': 1.2755102040816327e-05, 'epoch': 0.32}\n",
      "{'loss': 0.0282, 'learning_rate': 1.9387755102040817e-05, 'epoch': 0.64}\n",
      "{'loss': 0.0244, 'learning_rate': 1.7970521541950115e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.022, 'learning_rate': 1.655328798185941e-05, 'epoch': 1.28}\n",
      "{'loss': 0.0212, 'learning_rate': 1.5136054421768709e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0179, 'learning_rate': 1.3718820861678006e-05, 'epoch': 1.91}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0155, 'learning_rate': 1.2301587301587303e-05, 'epoch': 2.23}\n",
      "{'loss': 0.0143, 'learning_rate': 1.0884353741496601e-05, 'epoch': 2.55}\n",
      "{'loss': 0.0132, 'learning_rate': 9.467120181405896e-06, 'epoch': 2.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0114, 'learning_rate': 8.049886621315193e-06, 'epoch': 3.19}\n",
      "{'loss': 0.0107, 'learning_rate': 6.63265306122449e-06, 'epoch': 3.51}\n",
      "{'loss': 0.01, 'learning_rate': 5.2154195011337876e-06, 'epoch': 3.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0087, 'learning_rate': 3.7981859410430844e-06, 'epoch': 4.15}\n",
      "{'loss': 0.0087, 'learning_rate': 2.380952380952381e-06, 'epoch': 4.46}\n",
      "{'loss': 0.0079, 'learning_rate': 9.63718820861678e-07, 'epoch': 4.78}\n",
      "{'train_runtime': 3337.8783, 'train_samples_per_second': 18.789, 'train_steps_per_second': 1.174, 'train_loss': 0.03988697303801167, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics, \n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(\"distil_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model overview: \n",
      "LangID(\n",
      "  (word_embeddings): Embedding(19674, 100)\n",
      "  (bilstm): LSTM(100, 50, batch_first=True)\n",
      "  (hidden_to_tag): Linear(in_features=50, out_features=8, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LangID(nn.Module):\n",
    "    def __init__(self, embed_dim, lstm_dim, vocab_dim):\n",
    "        super(LangID, self).__init__()\n",
    "        self.word_embeddings = nn.Embedding(vocab_dim, embed_dim)\n",
    "        self.bilstm = nn.LSTM(embed_dim, lstm_dim, bidirectional=False, batch_first=True)\n",
    "        self.hidden_to_tag = nn.Linear(lstm_dim, NTAGS)\n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        word_vectors = self.word_embeddings(inputs)\n",
    "        bilstm_out, _ = self.bilstm(word_vectors)\n",
    "        y = self.hidden_to_tag(bilstm_out)\n",
    "        return y # softmax this in order to get probs, check out for axis, has to sum up to 1\n",
    "    \n",
    "    def predict(self, inputs):\n",
    "        with torch.no_grad():\n",
    "            data_feats, data_labels = data2feats(inputs, token_vocab, label_vocab)\n",
    "\n",
    "            logits = self.forward(data_feats)\n",
    "            probabilities = self.softmax(logits)\n",
    "            return torch.argmax(probabilities, 2)\n",
    "\n",
    "\n",
    "# define the model\n",
    "langid_model = LangID(DIM_EMBEDDING, LSTM_HIDDEN, NWORDS)\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0, reduction='sum')\n",
    "optimizer = optim.Adam(langid_model.parameters(), lr=LEARNING_RATE)\n",
    "print('model overview: ')\n",
    "print(langid_model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to batches\n",
    "num_batches = int(len(train_features)/BATCH_SIZE)\n",
    "train_feats_batches = train_features[:BATCH_SIZE*num_batches].view(num_batches, BATCH_SIZE, max_len)\n",
    "train_labels_batches = train_labels[:BATCH_SIZE*num_batches].view(num_batches, BATCH_SIZE, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   loss      Train acc.\n",
      "0       277.50    0.9401\n",
      "1       114.62    0.9677\n",
      "2       61.09     0.9822\n",
      "3       37.46     0.9893\n",
      "4       25.42     0.9930\n"
     ]
    }
   ],
   "source": [
    "print('epoch   loss      Train acc.')\n",
    "for epoch in range(EPOCHS):\n",
    "    langid_model.train() \n",
    "    langid_model.zero_grad()\n",
    "\n",
    "    # Loop over batches\n",
    "    loss = 0\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for batchIdx in range(0, num_batches):\n",
    "        output_scores = langid_model.forward(train_feats_batches[batchIdx])\n",
    "        \n",
    "        output_scores = output_scores.view(BATCH_SIZE * max_len, -1)\n",
    "        flat_labels = train_labels_batches[batchIdx].view(BATCH_SIZE * max_len)\n",
    "        batch_loss = loss_function(output_scores, flat_labels)\n",
    "\n",
    "        predicted_labels = torch.argmax(output_scores, 1)\n",
    "        predicted_labels = predicted_labels.view(BATCH_SIZE, max_len)\n",
    "\n",
    "        # Run backward pass\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        langid_model.zero_grad()\n",
    "        loss += batch_loss.item()\n",
    "        # Update the number of correct tags and total tags\n",
    "        for gold_sent, pred_sent in zip(train_labels_batches[batchIdx], predicted_labels):\n",
    "            for gold_label, pred_label in zip(gold_sent, pred_sent):\n",
    "                if gold_label != 0:\n",
    "                    total += 1\n",
    "                    if gold_label == pred_label:\n",
    "                        match+= 1\n",
    "    print('{0: <8}{1: <10}{2}'.format(epoch, '{:.2f}'.format(loss/num_batches), '{:.4f}'.format(match / total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load fine tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our finetuned model\n",
    "fine_tuned = AutoModelForTokenClassification.from_pretrained(\"distil_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(fine_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our model on dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "def run_eval(feats_batches, labels_batches, model):\n",
    "    if model == 'LSTM':\n",
    "        langid_model.eval()\n",
    "    match = 0\n",
    "    total = 0\n",
    "    for sents, labels in zip(feats_batches, labels_batches):\n",
    "        if model == 'LSTM':\n",
    "            output_scores = langid_model.forward(sents)\n",
    "            predicted_tags  = torch.argmax(output_scores, 2)\n",
    "        elif model == 'BERT':\n",
    "            output_scores = fine_tuned(sents) \n",
    "            predicted_tags  = torch.argmax(output_scores.logits, dim=-1)\n",
    "        else:\n",
    "            print('Please specify supported model.')\n",
    "            return\n",
    "        for sentence in sents:\n",
    "            sentenceWords = []\n",
    "            for wordIndex in sentence:\n",
    "                sentenceWords.append(token_vocab.getWord(wordIndex.item()))\n",
    "            sentences.append(sentenceWords)\n",
    "        for sentenceTags in predicted_tags:\n",
    "                predictionTagOneSentence = []\n",
    "                for tag in sentenceTags:\n",
    "                    predictionTagOneSentence.append(label_vocab.idx2word[tag.item()])\n",
    "                predictions.append(predictionTagOneSentence)\n",
    "        for goldSent, predSent in zip(labels, predicted_tags):\n",
    "            for goldLabel, predLabel in zip(goldSent, predSent):\n",
    "                if goldLabel.item() != 0:\n",
    "                    total += 1\n",
    "                    if goldLabel.item() == predLabel.item():\n",
    "                        match+= 1\n",
    "    return(match/total)\n",
    "\n",
    "dev_feats, dev_labels = data2feats(dev_data, token_vocab, label_vocab)\n",
    "num_batches_dev = int(len(dev_feats)/BATCH_SIZE)\n",
    "\n",
    "dev_feats_batches = dev_feats[:BATCH_SIZE*num_batches_dev].view(num_batches_dev, BATCH_SIZE, max_len)\n",
    "dev_labels_batches = dev_labels[:BATCH_SIZE*num_batches_dev].view(num_batches_dev, BATCH_SIZE, max_len)\n",
    "score = run_eval(dev_feats_batches, dev_labels_batches, 'BERT')\n",
    "\n",
    "print('Accuracy for dev data: {:.4f}'.format(score))\n",
    "\n",
    "with open('bert_predictions_dev.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/en_ewt-ud-dev.iob2 data/bert_predictions_dev.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "dataset = []\n",
    "for sentence in dev_data:\n",
    "    dataset.append(\" \".join(sentence[0]))\n",
    "pdataset = list(nlp.pipe(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed names data: \u001b[0m 0.8046\n"
     ]
    }
   ],
   "source": [
    "new_sentences = []\n",
    "new_tagged_dataset = []\n",
    "# nsamples = how many 'name' sentences we want to take into account\n",
    "# n = represents number of sentences that we want to generate for each 'name' sentence\n",
    "t_names = Perturb.perturb(pdataset, Perturb.change_names, n=2)\n",
    "original_sentences = []\n",
    "for sentences in t_names.data:\n",
    "    original_sentences.append(sentences[0])\n",
    "# Tokenize\n",
    "for sentences in t_names.data:\n",
    "    for sentence in sentences:\n",
    "        new_sentences.append(sentence.split())\n",
    "# Assign NER tags to the generated data\n",
    "for index, new_sentence in enumerate(new_sentences):\n",
    "    for sentence in dev_data:\n",
    "        if new_sentence == sentence[0]:\n",
    "            ner_tag = sentence[1]\n",
    "    if index % 3 != 0:\n",
    "        new_tagged_dataset.append((new_sentences[index],ner_tag))\n",
    "\n",
    "# Create gold labels file: index<TAB>word<TAB>label. \n",
    "with open('gold_names.iob2', 'w') as f:\n",
    "    for sentence, tag in new_tagged_dataset:\n",
    "        for index, (token, pred) in enumerate(zip(sentence, tag)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "changed_names_feats, dev_names_labels = data2feats(new_tagged_dataset, token_vocab, label_vocab)\n",
    "num_batches_changed_names = int(len(changed_names_feats)/BATCH_SIZE)\n",
    "\n",
    "changed_names_feats_batches = changed_names_feats[:BATCH_SIZE*num_batches_changed_names].view(num_batches_changed_names, BATCH_SIZE, max_len)\n",
    "changed_names_labels_batches = dev_names_labels[:BATCH_SIZE*num_batches_changed_names].view(num_batches_changed_names, BATCH_SIZE, max_len)\n",
    "score = run_eval(changed_names_feats_batches, changed_names_labels_batches, 'BERT')\n",
    "\n",
    "print('\\033[32mAccuracy for changed names data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open('bert_predictions_names.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "# python3 span_f1.py data/gold_names.iob2 data/bert_predictions_names.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed location data: \u001b[0m 0.8827\n"
     ]
    }
   ],
   "source": [
    "new_sentences = []\n",
    "new_tagged_dataset = []\n",
    "# nsamples = how many 'name' sentences we want to take into account\n",
    "# n = represents number of sentences that we want to generate for each 'name' sentence\n",
    "t_location = Perturb.perturb(pdataset, Perturb.change_location, n=2)\n",
    "original_sentences = []\n",
    "for sentences in t_location.data:\n",
    "    original_sentences.append(sentences[0])\n",
    "# Tokenize\n",
    "for sentences in t_location.data:\n",
    "    for sentence in sentences:\n",
    "        new_sentences.append(sentence.split())\n",
    "# Assign NER tags to the generated data\n",
    "for index, new_sentence in enumerate(new_sentences):\n",
    "    for sentence in dev_data:\n",
    "        if new_sentence == sentence[0]:\n",
    "            ner_tag = sentence[1]\n",
    "    if index % 3 != 0:\n",
    "        new_tagged_dataset.append((new_sentences[index],ner_tag))\n",
    "\n",
    "# Create gold labels file: index<TAB>word<TAB>label. \n",
    "with open('gold_location.iob2', 'w') as f:\n",
    "    for sentence, tag in new_tagged_dataset:\n",
    "        for index, (token, pred) in enumerate(zip(sentence, tag)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "changed_location_feats, dev_location_labels = data2feats(new_tagged_dataset, token_vocab, label_vocab)\n",
    "num_batches_changed_location = int(len(changed_location_feats)/BATCH_SIZE)\n",
    "\n",
    "changed_location_feats_batches = changed_location_feats[:BATCH_SIZE*num_batches_changed_location].view(num_batches_changed_location, BATCH_SIZE, max_len)\n",
    "changed_location_labels_batches = dev_location_labels[:BATCH_SIZE*num_batches_changed_location].view(num_batches_changed_location, BATCH_SIZE, max_len)\n",
    "score = run_eval(changed_location_feats_batches, changed_location_labels_batches, 'BERT')\n",
    "\n",
    "print('\\033[32mAccuracy for changed location data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open('bert_predictions_location.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/gold_location.iob2 data/bert_predictions_location.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed number data: \u001b[0m 0.9080\n"
     ]
    }
   ],
   "source": [
    "new_sentences = []\n",
    "new_tagged_dataset = []\n",
    "# nsamples = how many 'name' sentences we want to take into account\n",
    "# n = represents number of sentences that we want to generate for each 'name' sentence\n",
    "t_number = Perturb.perturb(pdataset, Perturb.change_number, n=2)\n",
    "original_sentences = []\n",
    "for sentences in t_number.data:\n",
    "    original_sentences.append(sentences[0])\n",
    "# Tokenize\n",
    "for sentences in t_number.data:\n",
    "    for sentence in sentences:\n",
    "        new_sentences.append(sentence.split())\n",
    "# Assign NER tags to the generated data\n",
    "for index, new_sentence in enumerate(new_sentences):\n",
    "    for sentence in dev_data:\n",
    "        if new_sentence == sentence[0]:\n",
    "            ner_tag = sentence[1]\n",
    "    if index % 3 != 0:\n",
    "        new_tagged_dataset.append((new_sentences[index],ner_tag))\n",
    "\n",
    "# Create gold labels file: index<TAB>word<TAB>label. \n",
    "with open('gold_numbers.iob2', 'w') as f:\n",
    "    for sentence, tag in new_tagged_dataset:\n",
    "        for index, (token, pred) in enumerate(zip(sentence, tag)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "changed_number_feats, dev_numbers_labels = data2feats(new_tagged_dataset, token_vocab, label_vocab)\n",
    "num_batches_changed_number = int(len(changed_number_feats)/BATCH_SIZE)\n",
    "\n",
    "changed_number_feats_batches = changed_number_feats[:BATCH_SIZE*num_batches_changed_number].view(num_batches_changed_number, BATCH_SIZE, max_len)\n",
    "changed_number_labels_batches = dev_numbers_labels[:BATCH_SIZE*num_batches_changed_number].view(num_batches_changed_number, BATCH_SIZE, max_len)\n",
    "score = run_eval(changed_number_feats_batches, changed_number_labels_batches, 'BERT')\n",
    "\n",
    "print('\\033[32mAccuracy for changed number data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open('bert_predictions_numbers.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/gold_numbers.iob2 data/bert_predictions_numbers.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evuluating LSTM on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for dev data: 0.9603\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "score = run_eval(dev_feats_batches, dev_labels_batches, 'LSTM')\n",
    "\n",
    "print('Accuracy for dev data: {:.4f}'.format(score))\n",
    "\n",
    "with open('lstm_predictions_dev.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/en_ewt-ud-dev.iob2 data/lstm_predictions_dev.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change names for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed names data: \u001b[0m 0.9117\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "score = run_eval(changed_names_feats_batches, changed_names_labels_batches, 'LSTM')\n",
    "\n",
    "print('\\033[32mAccuracy for changed names data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open('lstm_predictions_names.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# python3 span_f1.py data/gold_names.iob2 data/lstm_predictions_names.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change location for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed location data: \u001b[0m 0.9222\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "score = run_eval(changed_location_feats_batches, changed_location_labels_batches, 'LSTM')\n",
    "\n",
    "print('\\033[32mAccuracy for changed location data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open('lstm_predictions_location.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/gold_location.iob2 data/lstm_predictions_location.iob2 <- run this in terminal to get span f1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change numbers for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mAccuracy for changed number data: \u001b[0m 0.9381\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "predictions = []\n",
    "\n",
    "score = run_eval(changed_number_feats_batches, changed_number_labels_batches, 'LSTM')\n",
    "\n",
    "print('\\033[32mAccuracy for changed number data: \\033[0m {:.4f}'.format(score))\n",
    "\n",
    "with open('lstm_predictions_numbers.iob2', 'w') as f:\n",
    "    for sent_tokens, sent_preds in zip(sentences, predictions):\n",
    "        for index, (token, pred) in enumerate(zip(sent_tokens, sent_preds)):\n",
    "            f.write(f\"{index}\\t{token}\\t{pred}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "# python3 span_f1.py data/gold_numbers.iob2 data/lstm_predictions_numbers.iob2 <- run this in terminal to get span f1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
